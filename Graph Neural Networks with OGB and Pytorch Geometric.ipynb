{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85e104f0-dbc0-40c8-8b21-3160433535a1",
   "metadata": {},
   "source": [
    "# Graph Neural Networks with OGB and Pytorch Geometric\n",
    "\n",
    "In this notebook we are going to implement a Graph Neural Network using pytorch geometric and the Open Graph Benchmark. The goal of this notebook is giving general directions for anyone wishing to start in this kind of development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e3ee95f-a18a-4bed-aa8e-1e3657d4f64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch_geometric.nn import MessagePassing, SAGEConv\n",
    "from ogb.nodeproppred import Evaluator, PygNodePropPredDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb037f1a-5949-4ac3-9522-5d35cf2b7c28",
   "metadata": {},
   "source": [
    "## Open Graph Benchmark (OGB)\n",
    "\n",
    "The OGB is a collection of realistic, large-scale, and diverse benchmark datasets for machine learning on graphs. It gives us curated datasets and formalize the splitting and evaluation process for prediction tasks on those datasets.\n",
    "\n",
    "One can imagine it as the ImageNet dataset for computer vision. Their goal is to create a standard way of evaluating advances on the Graph Learning area.\n",
    "\n",
    "We will use the 'ogbn-arxiv' dataset, which is a node prediction dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c7c1658-1566-459e-8fe5-71da8b206caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.08 GB: 100%|██████████| 81/81 [01:09<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting networks\\arxiv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading necessary files...\n",
      "This might take a while.\n",
      "Processing graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting graphs into PyG objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PygNodePropPredDataset()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dataset = 'ogbn-arxiv'\n",
    "\n",
    "# This will download the ogbn-arxiv to the 'networks' folder\n",
    "dataset = PygNodePropPredDataset(name=target_dataset, root='networks')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6de9d0fd-7541-4c35-99dc-3b8457ff1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data we are going to use can be extracted from the dataset as follows:\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d259586-7339-4fb6-ac99-2f6b4154728a",
   "metadata": {},
   "source": [
    "For graph prediction tasks, each value from the dataset would be a different graph. Here we are dealing with only one graph saved on the 'data' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08384f4a-9e04-4e98-b03a-0c4efb50cca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(num_nodes=169343, edge_index=[2, 1166243], x=[169343, 128], node_year=[169343, 1], y=[169343, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe60bd-5733-4095-9a46-6fba9a652471",
   "metadata": {},
   "source": [
    "This is a Data class from Pytorch. Here we can see some information: the number of nodes in the graph, the adjacency list (called edge_index), the feature matrix of the graph (x), the year for each node and the prediction target (y).\n",
    "\n",
    "This is what we are going to use to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86969f82-5de2-45b9-b134-3db98cd9d605",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = dataset.get_idx_split() \n",
    "        \n",
    "train_idx = split_idx['train']\n",
    "valid_idx = split_idx['valid']\n",
    "test_idx = split_idx['test']\n",
    "        \n",
    "train_loader = NeighborLoader(data, input_nodes=train_idx,\n",
    "                              shuffle=True, num_workers=os.cpu_count() - 2,\n",
    "                              batch_size=1024, num_neighbors=[30] * 2)\n",
    "\n",
    "total_loader = NeighborLoader(data, input_nodes=None, num_neighbors=[-1],\n",
    "                                           batch_size=4096, shuffle=False,\n",
    "                                           num_workers=os.cpu_count() - 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9d5d48-23a0-4949-9f18-944762641634",
   "metadata": {},
   "source": [
    "## Pytorch Geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc69732-d958-43b1-a398-3f73cdfa297e",
   "metadata": {},
   "source": [
    "### Creating the GNN\n",
    "\n",
    "We are going to use a SAGE GNN for this notebook. We will allow the number of layers to be parametrized, but will use only two here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc997eba-cfd6-4ce4-ad6a-6e1d70913da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels,\n",
    "                 hidden_channels, out_channels,\n",
    "                 n_layers=2):\n",
    "        \n",
    "        super(SAGE, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        self.layers_bn = torch.nn.ModuleList()\n",
    "\n",
    "        if n_layers == 1:\n",
    "            self.layers.append(SAGEConv(in_channels, out_channels, normalize=False))\n",
    "        elif n_layers == 2:\n",
    "            self.layers.append(SAGEConv(in_channels, hidden_channels, normalize=False))\n",
    "            self.layers_bn.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "            self.layers.append(SAGEConv(hidden_channels, out_channels, normalize=False))\n",
    "        else:\n",
    "            self.layers.append(SAGEConv(in_channels, hidden_channels, normalize=False))\n",
    "            self.layers_bn.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "\n",
    "            for _ in range(n_layers - 2):\n",
    "                self.layers.append(SAGEConv(hidden_channels, hidden_channels, normalize=False))\n",
    "                self.layers_bn.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "            \n",
    "            self.layers.append(SAGEConv(hidden_channels, out_channels, normalize=False))\n",
    "            \n",
    "        for layer in self.layers:\n",
    "            layer.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        if len(self.layers) > 1:\n",
    "            looper = self.layers[:-1]\n",
    "        else:\n",
    "            looper = self.layers\n",
    "        \n",
    "        for i, layer in enumerate(looper):\n",
    "            x = layer(x, edge_index)\n",
    "            try:\n",
    "                x = self.layers_bn[i](x)\n",
    "            except Exception as e:\n",
    "                abs(1)\n",
    "            finally:\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "        \n",
    "        if len(self.layers) > 1:\n",
    "            x = self.layers[-1](x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=-1), torch.var(x)\n",
    "    \n",
    "    def inference(self, total_loader, device):\n",
    "        xs = []\n",
    "        var_ = []\n",
    "        for batch in total_loader:\n",
    "            out, var = self.forward(batch.x.to(device), batch.edge_index.to(device))\n",
    "            out = out[:batch.batch_size]\n",
    "            xs.append(out.cpu())\n",
    "            var_.append(var.item())\n",
    "        \n",
    "        out_all = torch.cat(xs, dim=0)\n",
    "        \n",
    "        return out_all, var_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a60a67-1695-40f4-91fd-ea1c91e6dd1f",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19c341c0-17ac-48e1-a1dd-a3ac2db454e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAGE(data.x.shape[1], 256, dataset.num_classes, n_layers=2)\n",
    "model.to(device)\n",
    "epochs = 100\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'max', patience=7)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57a98c9a-6e43-49bc-926f-faabecf028a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device):\n",
    "    evaluator = Evaluator(name=target_dataset)\n",
    "    model.eval()\n",
    "    out, var = model.inference(total_loader, device)\n",
    "\n",
    "    y_true = data.y.cpu()\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "    train_acc = evaluator.eval({\n",
    "        'y_true': y_true[split_idx['train']],\n",
    "        'y_pred': y_pred[split_idx['train']],\n",
    "    })['acc']\n",
    "    val_acc = evaluator.eval({\n",
    "        'y_true': y_true[split_idx['valid']],\n",
    "        'y_pred': y_pred[split_idx['valid']],\n",
    "    })['acc']\n",
    "    test_acc = evaluator.eval({\n",
    "        'y_true': y_true[split_idx['test']],\n",
    "        'y_pred': y_pred[split_idx['test']],\n",
    "    })['acc']\n",
    "\n",
    "    return train_acc, val_acc, test_acc, torch.mean(torch.Tensor(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "823aeb89-df10-4230-a7a8-751fce764566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01:   0%|          | 0/90941 [05:25<?, ?it/s]\n",
      "\n",
      "Epoch 01:   0%|          | 0/90941 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 01:   1%|          | 1024/90941 [02:54<4:15:12,  5.87it/s]\u001b[A\n",
      "Epoch 01:   3%|▎         | 3072/90941 [02:54<1:04:43, 22.63it/s]\u001b[A\n",
      "Epoch 01:   6%|▌         | 5120/90941 [02:54<30:45, 46.50it/s]  \u001b[A\n",
      "Epoch 01:  10%|█         | 9216/90941 [02:54<11:53, 114.56it/s]\u001b[A\n",
      "Epoch 01:  14%|█▎        | 12288/90941 [02:54<07:00, 187.11it/s]\u001b[A\n",
      "Epoch 01:  17%|█▋        | 15360/90941 [02:55<04:24, 286.01it/s]\u001b[A\n",
      "Epoch 01:  21%|██▏       | 19456/90941 [02:55<02:29, 478.04it/s]\u001b[A\n",
      "Epoch 01:  26%|██▌       | 23552/90941 [02:55<01:29, 748.97it/s]\u001b[A\n",
      "Epoch 01:  30%|███       | 27648/90941 [02:55<00:56, 1128.32it/s]\u001b[A\n",
      "Epoch 01:  35%|███▍      | 31744/90941 [02:55<00:35, 1655.51it/s]\u001b[A\n",
      "Epoch 01:  39%|███▉      | 35840/90941 [02:56<00:23, 2374.78it/s]\u001b[A\n",
      "Epoch 01:  44%|████▍     | 39936/90941 [02:56<00:15, 3342.28it/s]\u001b[A\n",
      "Epoch 01:  48%|████▊     | 44032/90941 [02:56<00:10, 4623.79it/s]\u001b[A\n",
      "Epoch 01:  53%|█████▎    | 48128/90941 [02:56<00:06, 6265.34it/s]\u001b[A\n",
      "Epoch 01:  57%|█████▋    | 52224/90941 [02:56<00:04, 8325.54it/s]\u001b[A\n",
      "Epoch 01:  62%|██████▏   | 56320/90941 [02:56<00:03, 10818.83it/s]\u001b[A\n",
      "Epoch 01:  66%|██████▋   | 60416/90941 [02:56<00:02, 13605.65it/s]\u001b[A\n",
      "Epoch 01:  71%|███████   | 64512/90941 [02:56<00:01, 16579.03it/s]\u001b[A\n",
      "Epoch 01:  75%|███████▌  | 68608/90941 [02:56<00:01, 19810.57it/s]\u001b[A\n",
      "Epoch 01:  80%|███████▉  | 72704/90941 [02:57<00:00, 23072.96it/s]\u001b[A\n",
      "Epoch 01:  84%|████████▍ | 76800/90941 [02:57<00:00, 25703.70it/s]\u001b[A\n",
      "Epoch 01:  89%|████████▉ | 80896/90941 [02:57<00:00, 27706.91it/s]\u001b[A\n",
      "Epoch 01:  93%|█████████▎| 84992/90941 [02:57<00:00, 29539.13it/s]\u001b[A\n",
      "Epoch 01: 100%|██████████| 90941/90941 [02:58<00:00, 510.51it/s]  \u001b[A\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 28.00 MiB (GPU 0; 12.00 GiB total capacity; 3.12 GiB already allocated; 7.05 GiB free; 3.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[0;32m     30\u001b[0m approx_acc \u001b[38;5;241m=\u001b[39m total_correct \u001b[38;5;241m/\u001b[39m train_idx\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m train_acc, val_acc, test_acc, var \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Var: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(model, device)\u001b[0m\n\u001b[0;32m      2\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m Evaluator(name\u001b[38;5;241m=\u001b[39mtarget_dataset)\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m----> 4\u001b[0m out, var \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m y_true \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m      7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mSAGE.inference\u001b[1;34m(self, total_loader, device)\u001b[0m\n\u001b[0;32m     54\u001b[0m var_ \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m total_loader:\n\u001b[1;32m---> 56\u001b[0m     out, var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     out \u001b[38;5;241m=\u001b[39m out[:batch\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[0;32m     58\u001b[0m     xs\u001b[38;5;241m.\u001b[39mappend(out\u001b[38;5;241m.\u001b[39mcpu())\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mSAGE.forward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;28mabs\u001b[39m(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m---> 44\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\masters\\lib\\site-packages\\torch\\nn\\functional.py:1442\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1440\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1442\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 28.00 MiB (GPU 0; 12.00 GiB total capacity; 3.12 GiB already allocated; 7.05 GiB free; 3.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs):\n",
    "    model.train()\n",
    "\n",
    "    pbar = tqdm(total=train_idx.size(0))\n",
    "    pbar.set_description(f'Epoch {epoch:02d}')\n",
    "\n",
    "    total_loss = total_correct = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch_size = batch.batch_size\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out, _ = model(batch.x.to(device), batch.edge_index.to(device))\n",
    "        out = out[:batch_size]\n",
    "\n",
    "        batch_y = batch.y[:batch_size].to(device)\n",
    "        batch_y = torch.reshape(batch_y, (-1,))\n",
    "\n",
    "        loss = F.nll_loss(out, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss)\n",
    "        total_correct += int(out.argmax(dim=-1).eq(batch_y).sum())\n",
    "        pbar.update(batch.batch_size)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    loss = total_loss / len(train_loader)\n",
    "    approx_acc = total_correct / train_idx.size(0)\n",
    "\n",
    "    train_acc, val_acc, test_acc, var = test(model, device)\n",
    "    \n",
    "    print(f'Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}, Var: {var:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59448511-83a3-4800-b8ee-7ec11c148b59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
